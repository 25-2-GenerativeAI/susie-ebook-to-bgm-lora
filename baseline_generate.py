# baseline_generate.py
# Colabì—ì„œ ì‹¤í–‰ ì „ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜:
# !pip install diffusers transformers accelerate soundfile librosa torch torchaudio

import os
import json
import torch
import soundfile as sf
from tqdm import tqdm
import numpy as np
import argparse
from diffusers import AudioLDMPipeline

def load_json(path):
    with open(path, "r", encoding="utf-8") as f:
        return json.load(f)

def ensure_dir(d):
    os.makedirs(d, exist_ok=True)

def save_wav(wav_np, sr, path):
    sf.write(path, wav_np, samplerate=sr)

def generate_text_to_audio(model, text, seed=None, duration_sec=6, sr=16000, **kwargs):
    """
    AudioLDM ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ë¡œë¶€í„° BGM ì˜¤ë””ì˜¤ ìƒì„± (Baseline - í”„ë¡¬í”„íŠ¸ ì˜ì¡´ì )
    ë°˜í™˜: np.ndarray(float32, shape=(n_samples,)) - mono
    """
    if seed is not None:
        torch.manual_seed(seed)
        np.random.seed(seed)
    
    # Baseline: í…ìŠ¤íŠ¸ ë‚´ìš© ë°˜ì˜í•˜ë˜ ì•ˆì „í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‚¬ìš©
    bgm_prompt = f"instrumental music for {text[:80]}"
    
    print(f"Baseline BGM Prompt: {bgm_prompt}")
        
    # ë‹¤ì–‘ì„± í™•ë³´í•˜ë©´ì„œë„ ì•ˆì „í•œ íŒŒë¼ë¯¸í„°
    audio = model(
        bgm_prompt, 
        num_inference_steps=20,  # í’ˆì§ˆê³¼ ë‹¤ì–‘ì„± ê· í˜•
        audio_length_in_s=duration_sec,  # ì˜¤ë””ì˜¤ ê¸¸ì´ (ì´ˆ)
        guidance_scale=4.0,  # í…ìŠ¤íŠ¸ ë°˜ì˜ë„ ë†’ì´ë©´ì„œë„ ì•ˆì •ì„± ìœ ì§€
        negative_prompt="noise, static, distortion, glitch, vocals, singing, speech",  # ë…¸ì´ì¦ˆ ë° ë³´ì»¬ ì œì™¸
        generator=torch.Generator().manual_seed(seed) if seed is not None else None
    ).audios[0]    # 16kHzë¡œ ë¦¬ìƒ˜í”Œë§ì´ í•„ìš”í•œ ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ í™•ì¸
    if len(audio.shape) > 1:
        audio = audio[0]  # ì²« ë²ˆì§¸ ì±„ë„ë§Œ ì‚¬ìš© (mono)
    
    return audio

def main(args):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print("device:", device)

    # AudioLDM ëª¨ë¸ ë¡œë“œ
    print("Loading AudioLDM model...")
    model = AudioLDMPipeline.from_pretrained(
        "cvssp/audioldm", 
        torch_dtype=torch.float16 if device == "cuda" else torch.float32
    ).to(device)
    print("AudioLDM model loaded successfully!")

    # --- ê²½ë¡œ ì„¸íŒ… ---
    train_json = args.train_json  # data/a_data_train.json
    test_json = args.test_json    # data/a_data_test.json

    out_train = "output/baseline/train"
    out_test = "output/baseline/test"
    ensure_dir(out_train)
    ensure_dir(out_test)

    train_data = load_json(train_json)
    test_data = load_json(test_json)

    # ë‹¨ì¼ ì˜¤ë””ì˜¤ ìƒì„± ëª¨ë“œ
    if args.single_index is not None:
        print(f"Generating single audio for index {args.single_index}")
        
        # í•´ë‹¹ ì¸ë±ìŠ¤ ì°¾ê¸°
        target_item = None
        is_test = False
        
        # train ë°ì´í„°ì—ì„œ ì°¾ê¸° (0~199)
        for item in train_data:
            if item.get("scene_id") == args.single_index:
                target_item = item
                output_dir = out_train
                break
        
        # test ë°ì´í„°ì—ì„œ ì°¾ê¸° (200~232)
        if target_item is None:
            for item in test_data:
                if item.get("scene_id") == args.single_index:
                    target_item = item
                    output_dir = out_test
                    is_test = True
                    break
        
        if target_item is None:
            print(f"Error: Index {args.single_index} not found in data!")
            return
        
        # ì˜¤ë””ì˜¤ ìƒì„±
        idx = target_item.get("scene_id")
        text = target_item.get("text", "").strip()
        
        if not text:
            print(f"Error: Empty text for scene_id {idx}")
            return
        
        print(f"Text: {text[:100]}..." if len(text) > 100 else f"Text: {text}")
        print(f"Generating audio for scene_id {idx}...")
        
        seed = args.seed + idx if args.seed is not None else None
        wav = generate_text_to_audio(model, text, seed=seed, duration_sec=args.duration, sr=args.sr)
        out_path = os.path.join(output_dir, f"{idx:03d}_baseline.wav")
        save_wav(wav, args.sr, out_path)
        
        print(f"âœ… Audio saved: {out_path}")
        print(f"ğŸ“ Type: {'Test' if is_test else 'Train'} data")
        return
    
    # ì „ì²´ ë°°ì¹˜ ìƒì„± ëª¨ë“œ (ê¸°ì¡´ ë¡œì§)
    # --- TRAIN (0~199) ---
    print("Generating baseline train audios...")
    for item in tqdm(train_data, desc="Train audio generation"):
        idx = item.get("scene_id")
        text = item.get("text", "").strip()
        
        if not text:
            print(f"Warning: Empty text for scene_id {idx}, skipping...")
            continue
            
        # ìƒì„± íŒŒë¼ë¯¸í„°
        seed = args.seed + idx if args.seed is not None else None
        wav = generate_text_to_audio(model, text, seed=seed, duration_sec=args.duration, sr=args.sr)
        out_path = os.path.join(out_train, f"{idx:03d}_baseline.wav")
        save_wav(wav, args.sr, out_path)

    # --- TEST (200~232) ---
    print("Generating baseline test audios...")
    for item in tqdm(test_data, desc="Test audio generation"):
        idx = item.get("scene_id")
        text = item.get("text", "").strip()
        
        if not text:
            print(f"Warning: Empty text for scene_id {idx}, skipping...")
            continue
            
        seed = args.seed + idx if args.seed is not None else None
        wav = generate_text_to_audio(model, text, seed=seed, duration_sec=args.duration, sr=args.sr)
        out_path = os.path.join(out_test, f"{idx:03d}_baseline.wav")
        save_wav(wav, args.sr, out_path)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--train_json", default="data/a_data_train.json")
    parser.add_argument("--test_json", default="data/a_data_test.json")
    parser.add_argument("--sr", type=int, default=16000)
    parser.add_argument("--duration", type=int, default=6)  # ì´ˆ
    parser.add_argument("--seed", type=int, default=42)
    parser.add_argument("--single_index", type=int, help="Generate single audio for specific index (0~232)")
    args = parser.parse_args()
    main(args)
