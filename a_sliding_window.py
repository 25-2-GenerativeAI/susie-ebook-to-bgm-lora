import os
import re
import json
import numpy as np
import torch
from nltk.tokenize import sent_tokenize
from transformers import pipeline
from sklearn.metrics.pairwise import cosine_similarity

# -------------------------------
# í™˜ê²½ ì„¤ì •
# -------------------------------
device = "cuda" if torch.cuda.is_available() else "cpu"
if device == "cpu":
    print("âš ï¸ WARNING: No GPU detected.")

# ê°ì • ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ
try:
    emotion_classifier = pipeline(
        "text-classification",
        model="SamLowe/roberta-base-go_emotions",
        return_all_scores=True,
        device=0 if device == "cuda" else -1
    )
    print("âœ… Emotion Classifier loaded.")
except Exception as e:
    emotion_classifier = None
    print(f"ğŸš¨ Emotion Classifier failed: {e}")

# -------------------------------
# íŒŒë¼ë¯¸í„°
# -------------------------------
WINDOW_SIZE = 5
K_STD_DEV = 1.5
EMOTION_THRESHOLD = 0.5

# -------------------------------
# í•¨ìˆ˜ ì •ì˜
# -------------------------------
def load_text(file_path: str) -> str:
    """í…ìŠ¤íŠ¸ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°"""
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"{file_path} not found.")
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read()

def get_emotion_vector(text):
    """í…ìŠ¤íŠ¸ ê°ì • ë²¡í„° ì¶”ì¶œ"""
    emotions = emotion_classifier(text, top_k=None, truncation=True)
    return np.array(sorted([e['score'] for e in emotions]))

def segment_text_by_emotion(text, window_size, k_std):
    """ê°ì • ë³€í™” ê¸°ë°˜ìœ¼ë¡œ ì”¬ ë¶„í• """
    text = re.sub(r'\s+', ' ', text).strip()
    sentences = sent_tokenize(text)

    if len(sentences) < window_size * 2:
        return [text]

    # ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ê¸°ë°˜ ê°ì • ë²¡í„° ê³„ì‚°
    emotion_vectors = [
        get_emotion_vector(" ".join(sentences[i:i+window_size]))
        for i in range(len(sentences) - window_size + 1)
    ]

    # ê°ì • ë³€í™”ëŸ‰ ê³„ì‚°
    change_scores = np.array([
        1 - cosine_similarity([v1], [v2])[0][0]
        for v1, v2 in zip(emotion_vectors, emotion_vectors[1:])
    ])

    threshold = np.mean(change_scores) + k_std * np.std(change_scores)
    split_indices = [i for i, score in enumerate(change_scores) if score > threshold]

    if not split_indices:
        return [text]

    # ì»·íŒ…
    scene_chunks, start_idx = [], 0
    for idx in split_indices:
        split_point = idx + int(window_size / 2)
        if split_point > start_idx:
            scene_chunks.append(" ".join(sentences[start_idx:split_point]))
            start_idx = split_point
    scene_chunks.append(" ".join(sentences[start_idx:]))

    # 10 ë‹¨ì–´ ì´ìƒë§Œ ìœ ì§€
    final_chunks = [chunk for chunk in scene_chunks if len(chunk.split()) > 10]
    return final_chunks

def analyze_emotional_intensity(text_chunk):
    """ì”¬ ë‹¨ìœ„ ê°ì • ë¶„ì„"""
    emotions = emotion_classifier(text_chunk, top_k=None, truncation=True)
    dominant = max(emotions, key=lambda x: x['score'])
    return dominant['label'], dominant['score']

# -------------------------------
# ì‹¤í–‰ë¶€
# -------------------------------
def main(input_file="data/a_data.txt", output_path="data/a_data_train.json"):
    if not emotion_classifier:
        print("ğŸš¨ Emotion classifier not available.")
        return

    # í…ìŠ¤íŠ¸ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°
    text_to_process = load_text(input_file)

    # ì”¬ ë¶„í• 
    emotional_chunks = segment_text_by_emotion(text_to_process, WINDOW_SIZE, K_STD_DEV)

    results = []
    for i, chunk in enumerate(emotional_chunks):
        dominant_emotion, score = analyze_emotional_intensity(chunk)
        results.append({
            "scene_id": i,
            "text": chunk
        })

    # JSON ì €ì¥
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)

    print(f"âœ… Results saved to {output_path}")

# -------------------------------
# ì‹¤í–‰
# -------------------------------
if __name__ == "__main__":
    import nltk

    # í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ ë‹¤ìš´ë¡œë“œ
    nltk.download("punkt")
    nltk.download("punkt_tab")

    main()
